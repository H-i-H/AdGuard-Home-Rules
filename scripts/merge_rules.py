import os
import re
from pathlib import Path
from typing import Set, Optional

def is_valid_domain(domain: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆåŸŸåï¼ˆæ›´å®½æ¾ï¼‰"""
    if not domain or '.' not in domain:
        return False

    # å…è®¸å­—æ¯ã€æ•°å­—ã€è¿žå­—ç¬¦ã€ä¸‹åˆ’çº¿ï¼ˆæŸäº›å†…éƒ¨ç³»ç»Ÿä½¿ç”¨ï¼‰
    # ä¸å¼ºåˆ¶è¦æ±‚é¡¶çº§åŸŸåé•¿åº¦ï¼ˆæ”¯æŒ .co.uk ç­‰ï¼‰
    pattern = r'^[a-zA-Z0-9_-]+(\.[a-zA-Z0-9_-]+)*$'
    return re.match(pattern, domain) is not None

def process_hosts_file(filepath: Path) -> Set[str]:
    """å¤„ç† hosts æ–‡ä»¶æ ¼å¼ï¼šæå– 127.0.0.1 æˆ– 0.0.0.0 åŽçš„åŸŸå"""
    rules = set()
    try:
        for line in filepath.read_text(encoding='utf-8', errors='ignore').splitlines():
            line = line.strip()
            if not line or line.startswith(('#', '!')):
                continue

            parts = line.split()
            if len(parts) >= 2 and parts[0] in ('127.0.0.1', '0.0.0.0'):
                domain = parts[1].lower()
                if is_valid_domain(domain):
                    rules.add(domain)
    except Exception as e:
        print(f"  âŒ Error processing {filepath}: {e}")
    return rules

def process_adguard_file(filepath: Path) -> Set[str]:
    """å¤„ç† AdGuard è§„åˆ™æ–‡ä»¶"""
    rules = set()
    try:
        for line in filepath.read_text(encoding='utf-8', errors='ignore').splitlines():
            line = line.strip()
            if not line or line.startswith(('!', '[')):
                continue

            # æ”¯æŒæ ¼å¼: ||domain^ å’Œ ||domain^$third-party
            domain = None
            if line.startswith('||'):
                # ç§»é™¤é€‰é¡¹éƒ¨åˆ†
                rule_part = line.split('^$')[0] if '^$' in line else line
                domain = rule_part[2:].strip()

            if domain and is_valid_domain(domain):
                rules.add(domain.lower())
    except Exception as e:
        print(f"  âŒ Error processing {filepath}: {e}")
    return rules

def detect_file_type(filepath: Path) -> str:
    """æ£€æµ‹æ–‡ä»¶ç±»åž‹ï¼ˆæ›´å¯é ï¼‰"""
    try:
        content = filepath.read_text(encoding='utf-8', errors='ignore')
        lines = content.splitlines()

        # æ£€æŸ¥å‰10è¡Œéžç©ºéžæ³¨é‡Šè¡Œ
        sample_lines = [
            line.strip() for line in lines[:20]
            if line.strip() and not line.startswith(('!', '#', '['))
        ]

        # ç»Ÿè®¡ç‰¹å¾
        has_adguard_format = any(
            line.startswith('||') and ('^' in line or '$' in line)
            for line in sample_lines
        )
        has_hosts_format = any(
            line.split()[0] in ('127.0.0.1', '0.0.0.0') if line.split() else False
            for line in sample_lines
        )

        if has_adguard_format and not has_hosts_format:
            return 'adguard'
        elif has_hosts_format and not has_adguard_format:
            return 'hosts'
        else:
            # é»˜è®¤æˆ–æ··åˆæ ¼å¼ï¼šå°è¯•ä¸¤ç§
            return 'mixed'
    except:
        return 'unknown'

def merge_category_rules(category: str) -> bool:
    """åˆå¹¶ç‰¹å®šåˆ†ç±»çš„è§„åˆ™"""
    print(f"  ðŸ”„ Merging {category} rules...")
    all_rules = set()
    source_dir = Path('sources') / category

    if not source_dir.exists():
        print(f"  âš ï¸  No sources directory: {source_dir}")
        return False

    files = list(source_dir.glob('*'))
    if not files:
        print(f"  âš ï¸  No files in {source_dir}")
        return False

    for filepath in files:
        if not filepath.is_file():
            continue

        print(f"    ðŸ“„ Processing: {filepath.name}")

        # æ£€æµ‹æ–‡ä»¶ç±»åž‹
        file_type = detect_file_type(filepath)
        print(f"      Detected format: {file_type}")

        if file_type == 'adguard':
            rules = process_adguard_file(filepath)
        elif file_type == 'hosts':
            rules = process_hosts_file(filepath)
        elif file_type == 'mixed':
            # å°è¯•ä¸¤ç§æ–¹å¼ï¼Œåˆå¹¶ç»“æžœ
            rules = process_adguard_file(filepath) | process_hosts_file(filepath)
        else:
            print(f"      âš ï¸  Unknown format, skipping")
            continue

        all_rules.update(rules)
        print(f"      âž• Extracted {len(rules)} rules")

    if not all_rules:
        print(f"  âš ï¸  No rules extracted for {category}")
        return False

    # ä¿å­˜åˆå¹¶åŽçš„è§„åˆ™
    output_dir = Path('filters')
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / f'{category}-blacklist.txt'

    try:
        # ä¿æŒåŽŸå§‹æ ¼å¼ï¼šå¦‚æžœæ˜¯ä»Žhostsè½¬æ¢ï¼Œä¿ç•™ä¸º||æ ¼å¼
        # ä½†è®°å½•åŽŸå§‹æ¥æºä¿¡æ¯
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"! Generated from {len(files)} sources\n")
            f.write(f"! Total unique rules: {len(all_rules)}\n")
            for rule in sorted(all_rules):
                f.write(f"||{rule}^\n")

        print(f"  ðŸ’¾ {category}: {len(all_rules)} unique rules saved to {output_file}")
        return True
    except Exception as e:
        print(f"  âŒ Error saving {output_file}: {e}")
        return False

def merge_all_categories(categories: Optional[list] = None) -> bool:
    """åˆå¹¶æ‰€æœ‰åˆ†ç±»è§„åˆ™"""
    print("ðŸ”„ Starting rule merging process...")

    if categories is None:
        categories = ['ads', 'malware', 'adult']

    # éªŒè¯sourcesç›®å½•
    if not Path('sources').exists():
        print("âŒ 'sources' directory not found!")
        return False

    success_count = 0

    for category in categories:
        if merge_category_rules(category):
            success_count += 1

    print(f"\nâœ… Merging complete: {success_count}/{len(categories)} categories processed")
    return success_count > 0

if __name__ == '__main__':
    merge_all_categories()
